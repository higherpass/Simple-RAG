{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG LLM Integration\n",
    "\n",
    "This notebook builds on `01_basic_rag.ipynb` and demonstrates how to integrate a RAG model with a Language Model (LLM) to generate full text responses.\n",
    "\n",
    "## Usage\n",
    "\n",
    "Uncomment and set the `ANTHROPIC_API_KEY` environment variable to your Anthropic API key if not set already in your environment.\n",
    "Set the `ANTRHOPIC_MODEL_NAME` to the model you want to use. The default is `claude-3-5-sonnet-20241022`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['ANTHROPIC_API_KEY'] = ''\n",
    "ANTHROPIC_MODEL_NAME = \"claude-3-5-sonnet-20241022\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is the same as in `01_basic_rag.ipynb` and sets up the text embeddings generator class `LocalEmbeddingGenerator`.  The example function has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "class LocalEmbeddingGenerator:\n",
    "    def __init__(self, embedding_dim=384):  # Using 384 dimensions as it's common for many embedding models\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.word2vec_model = None\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        # Download required NLTK data\n",
    "        import nltk\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('wordnet')\n",
    "        \n",
    "        # Initialize stop words\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Preprocess the input text.\"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stop words and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens \n",
    "                 if token not in self.stop_words and token not in string.punctuation]\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "    def train_word2vec(self, texts):\n",
    "        \"\"\"Train a Word2Vec model on the given texts.\"\"\"\n",
    "        # Preprocess all texts\n",
    "        print(texts)\n",
    "        processed_texts = [self.preprocess_text(text) for text in texts]\n",
    "        \n",
    "        # Train Word2Vec model\n",
    "        self.word2vec_model = Word2Vec(sentences=processed_texts, \n",
    "                                     vector_size=self.embedding_dim,\n",
    "                                     window=5,\n",
    "                                     min_count=1,\n",
    "                                     workers=4)\n",
    "\n",
    "    def generate_embedding(self, text):\n",
    "        \"\"\"Generate embedding for the input text.\"\"\"\n",
    "        if self.word2vec_model is None:\n",
    "            raise ValueError(\"Word2Vec model not trained. Please train the model first.\")\n",
    "        \n",
    "        # Preprocess the input text\n",
    "        tokens = self.preprocess_text(text)\n",
    "        \n",
    "        if not tokens:\n",
    "            return np.zeros(self.embedding_dim)\n",
    "        \n",
    "        # Get embeddings for each token\n",
    "        token_embeddings = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                token_embedding = self.word2vec_model.wv[token]\n",
    "                token_embeddings.append(token_embedding)\n",
    "            except KeyError:\n",
    "                continue\n",
    "        \n",
    "        if not token_embeddings:\n",
    "            return np.zeros(self.embedding_dim)\n",
    "        \n",
    "        # Average the token embeddings\n",
    "        final_embedding = np.mean(token_embeddings, axis=0)\n",
    "        \n",
    "        return final_embedding\n",
    "\n",
    "    def format_embedding(self, embedding):\n",
    "        \"\"\"Format the embedding vector as a comma-separated list in square brackets.\"\"\"\n",
    "        return f\"[{','.join(map(str, embedding.tolist()))}]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RAGSystem` class is used to generate the RAG model. It is unchanged from `01_basic_rag.ipynb`.\n",
    "\n",
    "In preparation for integrating the RAG model with a LLM, we're going to perform some additional preprocessing on the documents. The `EnhancedRAGSystem` class is used to generate the RAG model with the additional preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial Intelligence (AI) is revolutionizing various industries. It encompasses machine learning, which allows systems to learn from data and improve their performance over time. Deep learning, a subset of machine learning, uses neural networks with multiple layers to process complex patterns in data. Natural Language Processing (NLP) is another crucial component of AI that focuses on enabling computers to understand and process human language effectively. NLP applications include machine translation, sentiment analysis, and chatbots. Computer vision, another AI domain, allows machines to interpret and analyze visual information from the world, enabling applications like facial recognition and autonomous vehicles.']\n",
      "['AI has numerous applications across various sectors, including healthcare, finance, education, and entertainment. In healthcare, AI is used for tasks like disease diagnosis, personalized treatment planning, and drug discovery. Financial institutions leverage AI for fraud detection, algorithmic trading, and customer service chatbots. Educational institutions use AI for personalized learning experiences and improving student outcomes. The entertainment industry uses AI for content recommendation, personalized marketing, and creating immersive gaming experiences.']\n",
      "Query: What is natural language processing and its applications?\n",
      "\n",
      "Generated Context:\n",
      "[Source: Copilot_Autocomplete]\n",
      "AI has numerous applications across various sectors, including healthcare, finance, education, and entertainment. In healthcare, AI is used for tasks like disease diagnosis, personalized treatment planning, and drug discovery. Financial institutions leverage AI for fraud detection, algorithmic trading, and customer service chatbots. Educational institutions use AI for personalized learning experiences and improving student outcomes. The entertainment industry uses AI for content recommendation, personalized marketing, and creating immersive gaming experiences.\n",
      "\n",
      "[Source: AI_textbook]\n",
      "Artificial Intelligence (AI) is revolutionizing various industries. It encompasses machine learning, which allows systems to learn from data and improve their performance over time. Deep learning, a subset of machine learning, uses neural networks with multiple layers to process complex patterns in data. Natural Language Processing (NLP) is another crucial component of AI that focuses on enabling computers to understand and process human language effectively. NLP applications include machine translation, sentiment analysis, and chatbots. Computer vision, another AI domain, allows machines to interpret and analyze visual information from the world, enabling applications like facial recognition and autonomous vehicles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/craig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/craig/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/craig/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "\n",
    "class RAGSystem:\n",
    "    def __init__(self, embedding_dim=384):\n",
    "        self.embedding_generator = LocalEmbeddingGenerator(embedding_dim)\n",
    "        self.document_store: List[Dict] = []\n",
    "        self.document_embeddings: List[np.ndarray] = []\n",
    "\n",
    "    def add_documents(self, documents: List[str], metadata: List[Dict] = None):\n",
    "        \"\"\"\n",
    "        Add documents to the RAG system and generate their embeddings.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of document texts\n",
    "            metadata: Optional list of metadata dictionaries for each document\n",
    "        \"\"\"\n",
    "        # Train the embedding model on all documents\n",
    "        self.embedding_generator.train_word2vec(documents)\n",
    "\n",
    "        # Generate embeddings and store documents\n",
    "        for i, doc in enumerate(documents):\n",
    "            embedding = self.embedding_generator.generate_embedding(doc)\n",
    "            \n",
    "            doc_entry = {\n",
    "                'id': len(self.document_store),\n",
    "                'text': doc,\n",
    "                'metadata': metadata[i] if metadata else {}\n",
    "            }\n",
    "            \n",
    "            self.document_store.append(doc_entry)\n",
    "            self.document_embeddings.append(embedding)\n",
    "\n",
    "    def find_similar_documents(self, query: str, k: int = 3) -> List[Tuple[Dict, float]]:\n",
    "        \"\"\"\n",
    "        Find the k most similar documents to the query.\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            k: Number of documents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples containing (document, similarity_score)\n",
    "        \"\"\"\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = self.embedding_generator.generate_embedding(query)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = cosine_similarity(\n",
    "            [query_embedding],\n",
    "            self.document_embeddings\n",
    "        )[0]\n",
    "        \n",
    "        # Get top k similar documents\n",
    "        top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_k_indices:\n",
    "            results.append((self.document_store[idx], similarities[idx]))\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def save_to_disk(self, filepath: str):\n",
    "        \"\"\"Save the RAG system to disk.\"\"\"\n",
    "        data = {\n",
    "            'documents': self.document_store,\n",
    "            'embeddings': [emb.tolist() for emb in self.document_embeddings]\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "    def load_from_disk(self, filepath: str):\n",
    "        \"\"\"Load the RAG system from disk.\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        self.document_store = data['documents']\n",
    "        self.document_embeddings = [np.array(emb) for emb in data['embeddings']]\n",
    "\n",
    "    \n",
    "# Enhanced RAG system with chunking and context window management\n",
    "class EnhancedRAGSystem(RAGSystem):\n",
    "    def __init__(self, embedding_dim=384, chunk_size=200, chunk_overlap=50):\n",
    "        super().__init__(embedding_dim)\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "    def chunk_document(self, text: str) -> List[str]:\n",
    "        \"\"\"Split document into overlapping chunks.\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(words), self.chunk_size - self.chunk_overlap):\n",
    "            chunk = ' '.join(words[i:i + self.chunk_size])\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "        return chunks\n",
    "\n",
    "    def add_document_with_chunking(self, document: str, metadata: Dict = None):\n",
    "        \"\"\"Add a single document with chunking.\"\"\"\n",
    "        chunks = self.chunk_document(document)\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_metadata = metadata.copy() if metadata else {}\n",
    "            chunk_metadata.update({\n",
    "                'chunk_index': i,\n",
    "                'total_chunks': len(chunks),\n",
    "                'original_document': document[:100] + '...'  # Store first 100 chars as reference\n",
    "            })\n",
    "            \n",
    "            self.add_documents([chunk], [chunk_metadata])\n",
    "\n",
    "    def generate_context(self, query: str, max_tokens: int = 1000) -> str:\n",
    "        \"\"\"Generate context for the query by combining relevant chunks.\"\"\"\n",
    "        similar_docs = self.find_similar_documents(query, k=3)\n",
    "        \n",
    "        context = []\n",
    "        current_tokens = 0\n",
    "        \n",
    "        for doc, similarity in similar_docs:\n",
    "            doc_text = doc['text']\n",
    "            estimated_tokens = len(doc_text.split())\n",
    "            \n",
    "            if current_tokens + estimated_tokens <= max_tokens:\n",
    "                context.append(f\"[Source: {doc['metadata'].get('source', 'Unknown')}]\\n{doc_text}\")\n",
    "                current_tokens += estimated_tokens\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        return \"\\n\\n\".join(context)\n",
    "\n",
    "# Example usage of enhanced RAG system\n",
    "def enhanced_rag_example():\n",
    "    # Initialize enhanced RAG system\n",
    "    enhanced_rag = EnhancedRAGSystem()\n",
    "    \n",
    "    # Long document example\n",
    "    long_documents = [\n",
    "        \"\"\"\n",
    "        Artificial Intelligence (AI) is revolutionizing various industries. It encompasses \n",
    "        machine learning, which allows systems to learn from data and improve their performance \n",
    "        over time. Deep learning, a subset of machine learning, uses neural networks with multiple \n",
    "        layers to process complex patterns in data. Natural Language Processing (NLP) is another \n",
    "        crucial component of AI that focuses on enabling computers to understand and process \n",
    "        human language effectively. NLP applications include machine translation, sentiment \n",
    "        analysis, and chatbots. Computer vision, another AI domain, allows machines to interpret \n",
    "        and analyze visual information from the world, enabling applications like facial \n",
    "        recognition and autonomous vehicles.\n",
    "        \"\"\"\n",
    "        ,\n",
    "        \"\"\"\n",
    "        AI has numerous applications across various sectors, including healthcare, finance,\n",
    "        education, and entertainment. In healthcare, AI is used for tasks like disease diagnosis,\n",
    "        personalized treatment planning, and drug discovery. Financial institutions leverage AI\n",
    "        for fraud detection, algorithmic trading, and customer service chatbots. Educational\n",
    "        institutions use AI for personalized learning experiences and improving student outcomes.\n",
    "        The entertainment industry uses AI for content recommendation, personalized marketing, and\n",
    "        creating immersive gaming experiences.\n",
    "        \"\"\"\n",
    "    ]\n",
    "    \n",
    "    # Add the long document with chunking\n",
    "    enhanced_rag.add_document_with_chunking(\n",
    "        long_documents[0],\n",
    "        metadata={'source': 'AI_textbook', 'topic': 'AI_overview'}\n",
    "    )\n",
    "    enhanced_rag.add_document_with_chunking(\n",
    "        long_documents[1],\n",
    "        metadata={'source': 'Copilot_Autocomplete', 'topic': 'AI_Uses'}\n",
    "    )\n",
    "    \n",
    "    # Example query and context generation\n",
    "    query = \"What is natural language processing and its applications?\"\n",
    "    context = enhanced_rag.generate_context(query)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Generated Context:\")\n",
    "    print(context)\n",
    "\n",
    "enhanced_rag_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RAGPromptGenerator` is a class that generates prompts for the LLM based on the RAG model's output. \n",
    "\n",
    "`rag_prompt_example` shows how prompts are generated for the LLM including the RAG model's output.\n",
    "\n",
    "1. Initalize the `EnhancedRAGSystem` class.\n",
    "2. Setup test documents for the RAG model.\n",
    "3. Load the test documents.\n",
    "4. Initialize the `RAGPromptGenerator` class.\n",
    "5. Generate test prompts.\n",
    "6. Generate LLM Queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning algorithms can be categorized into supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data.']\n",
      "['Deep learning architectures include convolutional neural networks (CNNs) for image processing and recurrent neural networks (RNNs) for sequential data. Transformers have become popular for natural language processing tasks.']\n",
      "\n",
      "==================================================\n",
      "Query: What are the main types of machine learning?\n",
      "\n",
      "Generated Prompt:\n",
      "System: You are an AI expert. Provide detailed technical explanations.\n",
      "        \n",
      "        Context:\n",
      "        [Source: DL_guide]\n",
      "Deep learning architectures include convolutional neural networks (CNNs) for image processing and recurrent neural networks (RNNs) for sequential data. Transformers have become popular for natural language processing tasks.\n",
      "\n",
      "[Source: ML_textbook]\n",
      "Machine learning algorithms can be categorized into supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data.\n",
      "        \n",
      "        Human: What are the main types of machine learning?\n",
      "        \n",
      "        Assistant: Based on the provided context, I'll help answer your question.\n",
      "\n",
      "==================================================\n",
      "Query: Explain deep learning architectures\n",
      "\n",
      "Generated Prompt:\n",
      "System: You are an AI expert. Provide detailed technical explanations.\n",
      "        \n",
      "        Context:\n",
      "        [Source: DL_guide]\n",
      "Deep learning architectures include convolutional neural networks (CNNs) for image processing and recurrent neural networks (RNNs) for sequential data. Transformers have become popular for natural language processing tasks.\n",
      "\n",
      "[Source: ML_textbook]\n",
      "Machine learning algorithms can be categorized into supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data.\n",
      "        \n",
      "        Human: Explain deep learning architectures\n",
      "        \n",
      "        Assistant: Based on the provided context, I'll help answer your question.\n",
      "\n",
      "==================================================\n",
      "Query: What is the difference between supervised and unsupervised learning?\n",
      "\n",
      "Generated Prompt:\n",
      "System: You are an AI expert. Provide detailed technical explanations.\n",
      "        \n",
      "        Context:\n",
      "        [Source: DL_guide]\n",
      "Deep learning architectures include convolutional neural networks (CNNs) for image processing and recurrent neural networks (RNNs) for sequential data. Transformers have become popular for natural language processing tasks.\n",
      "\n",
      "[Source: ML_textbook]\n",
      "Machine learning algorithms can be categorized into supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data.\n",
      "        \n",
      "        Human: What is the difference between supervised and unsupervised learning?\n",
      "        \n",
      "        Assistant: Based on the provided context, I'll help answer your question.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/craig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/craig/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/craig/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "class RAGPromptGenerator:\n",
    "    def __init__(self, rag_system):\n",
    "        self.rag = rag_system\n",
    "    \n",
    "    def generate_prompt(self, query: str, system_prompt: str = None) -> str:\n",
    "        \"\"\"Generate a prompt for the LLM using retrieved context.\"\"\"\n",
    "        context = self.rag.generate_context(query)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        System: {system_prompt or 'You are a helpful AI assistant. Use the provided context to answer questions accurately. If the context does not contain relevant information, say so.'}\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "        \n",
    "        Human: {query}\n",
    "        \n",
    "        Assistant: Based on the provided context, I'll help answer your question.\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt.strip()\n",
    "\n",
    "def rag_prompt_example():\n",
    "    # Initialize the RAG system\n",
    "    rag = EnhancedRAGSystem()\n",
    "    \n",
    "    # Sample knowledge base\n",
    "    documents = [\n",
    "        {\n",
    "            'text': \"\"\"\n",
    "            Machine learning algorithms can be categorized into supervised learning, \n",
    "            unsupervised learning, and reinforcement learning. Supervised learning \n",
    "            uses labeled data to train models, while unsupervised learning finds \n",
    "            patterns in unlabeled data.\n",
    "            \"\"\",\n",
    "            'metadata': {\n",
    "                'source': 'ML_textbook',\n",
    "                'topic': 'machine_learning_basics'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'text': \"\"\"\n",
    "            Deep learning architectures include convolutional neural networks (CNNs) \n",
    "            for image processing and recurrent neural networks (RNNs) for sequential \n",
    "            data. Transformers have become popular for natural language processing tasks.\n",
    "            \"\"\",\n",
    "            'metadata': {\n",
    "                'source': 'DL_guide',\n",
    "                'topic': 'deep_learning_architectures'\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add documents with chunking\n",
    "    for doc in documents:\n",
    "        rag.add_document_with_chunking(doc['text'], doc['metadata'])\n",
    "    \n",
    "    # Initialize prompt generator\n",
    "    prompt_generator = RAGPromptGenerator(rag)\n",
    "    \n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"What are the main types of machine learning?\",\n",
    "        \"Explain deep learning architectures\",\n",
    "        \"What is the difference between supervised and unsupervised learning?\"\n",
    "    ]\n",
    "    \n",
    "    # Generate prompts for each query\n",
    "    for query in queries:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Query: {query}\")\n",
    "        prompt = prompt_generator.generate_prompt(\n",
    "            query,\n",
    "            system_prompt=\"You are an AI expert. Provide detailed technical explanations.\"\n",
    "        )\n",
    "        print(\"\\nGenerated Prompt:\")\n",
    "        print(prompt)\n",
    "\n",
    "rag_prompt_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally time to integrate the RAG model with the LLM. The `LLMInterface` is a base class we'll implement for the specific LLM we're using. In this case, we're using Anthropic's Claude. The `ClaudeInterface` class is a subclass of `LLMInterface` that implements the specific methods for Claude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import openai\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "class LLMInterface:\n",
    "    \"\"\"Base class for LLM interactions\"\"\"\n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ClaudeInterface(LLMInterface):\n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        self.api_key = api_key or os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
    "    \n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        try:\n",
    "            message = self.client.messages.create(\n",
    "                model=ANTHROPIC_MODEL_NAME,\n",
    "                max_tokens=1024,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }]\n",
    "            )\n",
    "            return message.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response from Claude: {str(e)}\")\n",
    "            return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    `RAGWithLLM` is a class that integrates the RAG model with the LLM. It uses the `RAGSystem` and `ClaudeInterface` classes to generate full text responses.  The `query` method takes the user query and generates a prompt including the RAG model's output and passes it to the LLM to generate a full text response.\n",
    "\n",
    "    The `example_rag_llm` function demonstrates how to use the `RAGWithLLM` class to generate full text responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is a high-level programming language known for its simplicity and readability. It supports multiple programming paradigms including procedural, object-oriented, and functional programming.']\n",
      "['Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.']\n",
      "\n",
      "Query: What is Python programming language?\n",
      "Error generating response from Claude: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"\n",
      "\n",
      "Response: \n",
      "\n",
      "Query: Explain machine learning concepts\n",
      "Error generating response from Claude: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"\n",
      "\n",
      "Response: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/craig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/craig/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/craig/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "class RAGWithLLM:\n",
    "    def __init__(self, rag_system, llm_interface: LLMInterface):\n",
    "        self.rag = rag_system\n",
    "        self.llm = llm_interface\n",
    "        self.prompt_generator = RAGPromptGenerator(rag_system)\n",
    "    \n",
    "    def query(self, user_query: str, system_prompt: Optional[str] = None) -> str:\n",
    "        # Generate RAG-enhanced prompt\n",
    "        enhanced_prompt = self.prompt_generator.generate_prompt(\n",
    "            user_query,\n",
    "            system_prompt\n",
    "        )\n",
    "        \n",
    "        # Get LLM response\n",
    "        response = self.llm.generate_response(enhanced_prompt)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Example usage:\n",
    "def example_rag_llm():\n",
    "    # Initialize RAG system\n",
    "    rag_system = EnhancedRAGSystem()\n",
    "    \n",
    "    # Sample documents\n",
    "    documents = [\n",
    "        {\n",
    "            'text': \"\"\"\n",
    "            Python is a high-level programming language known for its simplicity and readability.\n",
    "            It supports multiple programming paradigms including procedural, object-oriented,\n",
    "            and functional programming.\n",
    "            \"\"\",\n",
    "            'metadata': {'source': 'python_docs', 'topic': 'python_basics'}\n",
    "        },\n",
    "        {\n",
    "            'text': \"\"\"\n",
    "            Machine learning is a subset of artificial intelligence that enables systems\n",
    "            to learn and improve from experience without being explicitly programmed.\n",
    "            \"\"\",\n",
    "            'metadata': {'source': 'ml_guide', 'topic': 'ml_basics'}\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add documents to RAG system\n",
    "    for doc in documents:\n",
    "        rag_system.add_document_with_chunking(doc['text'], doc['metadata'])\n",
    "    \n",
    "    # Initialize LLM interface (choose either Claude or ChatGPT)\n",
    "    llm_interface = ClaudeInterface()  # or ChatGPTInterface()\n",
    "    \n",
    "    # Initialize RAG with LLM\n",
    "    rag_with_llm = RAGWithLLM(rag_system, llm_interface)\n",
    "    \n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"What is Python programming language?\",\n",
    "        \"Explain machine learning concepts\",\n",
    "    ]\n",
    "    \n",
    "    # Process queries\n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        response = rag_with_llm.query(\n",
    "            query,\n",
    "            system_prompt=\"You are an expert programmer and AI researcher. Provide detailed explanations.\"\n",
    "        )\n",
    "        print(f\"\\nResponse: {response}\")\n",
    "\n",
    "\n",
    "example_rag_llm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
